[Spark]
; https://openmldb.ai/docs/zh/main/reference/client_config/client_spark_config.html cli --spark_conf file
spark.driver.extraJavaOptions=-Dfile.encoding=utf-8
spark.executor.extraJavaOptions=-Dfile.encoding=utf-8

; hive test succeed
spark.sql.catalog.hive_prod=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.hive_prod.type=hive
spark.sql.catalog.hive_prod.uri=thrift://metastore:9083
; omit uri to use the same URI as Spark: hive.metastore.uris in hive-site.xml, so if I provide hive-site.xml in spark home or hive home, it will load other options in hive-site.xml
spark.sql.catalog.hive_prod.warehouse=hdfs://namenode:19000/user/hive/iceberg_storage # for create, no need for read/write

; hadoop test
spark.sql.catalog.hadoop_prod=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.hadoop_prod.type=hadoop
spark.sql.catalog.hadoop_prod.warehouse=hdfs://namenode:19000/user/hadoop_iceberg/

; rest test, needs iceberg-rest service
spark.sql.catalog.rest_prod=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.rest_prod.catalog-impl=org.apache.iceberg.rest.RESTCatalog
spark.sql.catalog.rest_prod.uri=http://iceberg-rest:8181/

; hive session needs any catalog above
; spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
; spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalogImplementation=in-memory

# spark.hadoop.hive.metastore.uris=thrift://hive-metastore:9083 # need more options in hive-site.xml, use the file
