kafka: {
  # kafka server host
  "bootstrap.servers": kafka:9092,
  # kafka connect rest api
  "connect.listeners": http://kafka-connect:8083,
  # the config to send message(json)
  "producer.properties": {
    # bootstrap.servers use the option kafka."bootstrap.servers"
    "key.serializer":"org.apache.kafka.common.serialization.StringSerializer",
    "value.serializer":"org.apache.kafka.common.serialization.StringSerializer"  
  }
}
openmldb:
  # use apiserver for admin, to avoid import jdbc jars. kafka use another option `connection.url` to connect, watch out.
  apiserver.address: openmldb-compose-api-1:9080
common_connector_conf: {
  "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
  "tasks.max": "1",
  # test db here, will be deleted before test, don't depend on the data in it.
  "connection.url": "jdbc:openmldb:///kafka_test?zk=openmldb-compose-zk-1:2181&zkPath=/openmldb"
}
run_case_id: "auto.schema" # run the first case by default
cases:
  - id: "auto.schema"
    append_conf: {
      "topics": "auto_schema",
      "name": "schema-connector",
      "auto.create": "false",
      "auto.schema": "true",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "false"
    }
    openmldb_ddl: "create table auto_schema(c1_int16 int16, c2_int32 int32, c3_int64 int64, c4_float float, c5_double double, c6_boolean bool, c7_string string, c8_date date, c9_timestamp timestamp)"
    files: 
      - "train.csv" # file path
    expect:
      table: "auto_schema"
    # can't check openmldb table result cuz too large, but it's simpler if we provide the table name
